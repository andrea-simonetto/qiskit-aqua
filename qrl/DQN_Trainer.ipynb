{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import pixiedust\n",
    "from gym.envs.registration import register\n",
    "from qiskit.aqua.components.optimizers import ADAM,COBYLA\n",
    "from qiskit.aqua.components.variational_forms.ry import RY\n",
    "from qiskit import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AccountProvider for IBMQ(hub='ibm-q', group='open', project='main')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='FrozenLakeNotSlippery-v0',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "    max_episode_steps=100,\n",
    "    reward_threshold=0.8196, # optimum = .8196, changing this seems have no influence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numStates(env):\n",
    "    if type(env.observation_space) != gym.spaces.tuple.Tuple:\n",
    "        return env.observation_space.n\n",
    "    dim_list = []\n",
    "    for sp in env.observation_space:\n",
    "        dim_list.append(sp.n)\n",
    "    dim_list = np.array(dim_list)\n",
    "    return dim_list.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Statehash(env,state):\n",
    "    if type(env.observation_space) != gym.spaces.tuple.Tuple:\n",
    "        return state\n",
    "    dim_list = []\n",
    "    for sp in env.observation_space:\n",
    "        dim_list.append(sp.n)\n",
    "    dim_list = np.array(dim_list)\n",
    "    h = 0\n",
    "    for i in range(len(dim_list)-1):\n",
    "        h += state[i]*dim_list[i+1:].prod()\n",
    "    h += state[-1]\n",
    "    return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QLearning(iterations,alpha, gamma, epsilon ,env):\n",
    "    returnlist = []\n",
    "    num_actions = env.action_space.n\n",
    "    num_states = get_numStates(env)\n",
    "    Q = np.zeros((num_states,num_actions))\n",
    "    for it in range(iterations):\n",
    "        state = env.reset()\n",
    "        R = 0\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            state_h = get_Statehash(env,state)\n",
    "            if np.random.random() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                candidates = np.where(Q[state_h] == np.max(Q[state_h]))[0]\n",
    "                action = np.random.choice(candidates)\n",
    "            statep, reward, done, info = env.step(action)\n",
    "            if reward == 0:\n",
    "                if done:\n",
    "                    reward = -0.2\n",
    "                else:\n",
    "                    reward = -0.01\n",
    "            else:\n",
    "                reward = 1.0\n",
    "            R *= gamma\n",
    "            R += reward\n",
    "            statep_h = get_Statehash(env,statep)\n",
    "            Q[state_h,action] += alpha*(reward + gamma*Q[statep_h].max() -Q[state_h,action])\n",
    "            state = statep\n",
    "            \n",
    "        returnlist.append(R)\n",
    "        if it%10000 == 0:\n",
    "            print('Iteration %d, Reward: %d'%(it,R))\n",
    "            \n",
    "    return returnlist, Q\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl, Q = QLearning(100000,1e-3,0.99,0.25,env)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     backend_sim = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "#     result = execute(qc, backend_sim, shots = shots).result()\n",
    "\n",
    "#     counts = result.get_counts()\n",
    "#     expect = np.zeros(nqbits)\n",
    "#     for c in counts :\n",
    "#         for n in range(nqbits):\n",
    "#             expect[n] += int(c[n])*counts[c]/shots\n",
    "#     #print(counts)\n",
    "#     return np.array(expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Qvalues(s_list,theta):\n",
    "#     shots = 1000\n",
    "#     nqbits = 4\n",
    "#     num_rep = 1\n",
    "#     qc_list = []\n",
    "#     for s in s_list:\n",
    "#         q = QuantumRegister(nqbits)\n",
    "#         c = ClassicalRegister(nqbits)\n",
    "#         qc = QuantumCircuit(q,c)\n",
    "\n",
    "#         d = np.binary_repr(int(s),nqbits)\n",
    "#         for j,i in enumerate(d):\n",
    "#             if i == '1':\n",
    "#                 qc.x(q[j])\n",
    "\n",
    "#         theta = theta.reshape((nqbits,3))\n",
    "\n",
    "#         for rep in range(num_rep):\n",
    "#             for i in range(1, nqbits):\n",
    "#                 qc.cx(q[i-1], q[i])\n",
    "\n",
    "#             for i in range(nqbits):\n",
    "#                 qc.u3( theta[i][0], theta[i][1], theta[i][2],q[i])\n",
    "\n",
    "\n",
    "\n",
    "#         #qc.measure(q,c)\n",
    "        \n",
    "#         qc_list.append(qc)\n",
    "    shots = 1000\n",
    "    depth = 4\n",
    "    qc_list = []\n",
    "    nqbits = 4\n",
    "    theta.flatten()\n",
    "    for s in s_list:\n",
    "        q = QuantumRegister(nqbits)\n",
    "        c = ClassicalRegister(nqbits)\n",
    "        qc = QuantumCircuit(q,c)\n",
    "\n",
    "        d = np.binary_repr(int(s),nqbits)\n",
    "        for j,i in enumerate(d):\n",
    "            if i == '1':\n",
    "                qc.x(q[j])\n",
    "        \n",
    "        #qc += RY(nqbits,1, [[0,1],[1,2],[2,3]], 'linear', None, 'cx').construct_circuit(theta)        \n",
    "        qc += RY(nqbits,depth).construct_circuit(theta,q)        \n",
    "        \n",
    "        #print(qc)\n",
    "        \n",
    "        qc_list.append(qc)\n",
    "\n",
    "\n",
    "    \n",
    "    backend_sim = Aer.get_backend('statevector_simulator')\n",
    "    qobj = assemble(qc_list,backend_sim)\n",
    "    #result_list = execute(qc_list, backend_sim, optimization_level = 0).result()\n",
    "    job = backend_sim.run(qobj)\n",
    "    result_list = job.result()\n",
    "    expect_list = []\n",
    "    for result in result_list.results:\n",
    "        proba = abs(np.array(result.data.statevector))**2\n",
    "\n",
    "\n",
    "        expect = np.zeros(nqbits)\n",
    "\n",
    "        for c in range(len(proba)):\n",
    "            cbin = np.binary_repr(int(c),nqbits)\n",
    "\n",
    "            for n in range(nqbits) : \n",
    "                if cbin[n] == '1':\n",
    "                    expect[n] += proba[c]\n",
    "                    \n",
    "        expect_list.append(np.flip(expect))\n",
    "                \n",
    "    #print(counts)\n",
    "    return expect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array([0.9,0.92,0.94,0.96,0.98,1.0] + [0]*6*3)\n",
    "q/2 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta):\n",
    "    su = 0\n",
    "    \n",
    "    s = [0] + [1] + [2] + [6] + [10] + [14]\n",
    "    a = np.array([[0, 0, 1, 0], [0, 0, 1, 0],  [0, 1, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "    \n",
    "    Qs = get_Qvalues(s,theta)\n",
    "    #q = np.array([0.9,0.92,0.94,0.96,0.98,1.0] + [0]*6*3)\n",
    "    #q = q/2 + 0.5\n",
    "    #a = [2,2,1,1,1,2] + [0]*6 + [3]*6 + [1,1,2,2,2,1]\n",
    "    #for i in range(len(q)):\n",
    "    #    su += (q[i] - Qs[i][int(a[i])])**2\n",
    "    #print(su/len(q))\n",
    "    su = (np.abs(Qs - a)).mean()\n",
    "    print(su)\n",
    "    return su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_original(theta):\n",
    "    su = 0\n",
    "    Qs = get_Qvalues([0,1,2,6,10,14]+ [0,1,2,6,10,14]*3,theta)\n",
    "    q = np.array([0.9,0.92,0.94,0.96,0.98,1.0] + [0]*6*3)\n",
    "    q = q/2 + 0.5\n",
    "    a = [2,2,1,1,1,2] + [0]*6 + [3]*6 + [1,1,2,2,2,1]\n",
    "    for i in range(len(q)):\n",
    "        su += (q[i] - Qs[i][int(a[i])])**2\n",
    "    print(su/len(q))\n",
    "    return su/len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(iterations,alpha, gamma, epsilon ,env,N,batchsize):\n",
    "    nqbits = 4\n",
    "    depth = 4\n",
    "    theta = np.array([2*np.pi*np.random.random(nqbits*(depth+1))]).flatten()\n",
    "    \n",
    "    #adam = ADAM(maxiter = iterations, lr = alpha)\n",
    "    cobyla = COBYLA(maxiter = iterations)\n",
    "    #theta,obj,_ = adam.optimize(2*nqbits,loss, initial_point = theta)\n",
    "    theta,obj,_ = cobyla.optimize(nqbits*(depth+1),loss, initial_point = theta)\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        print(s)\n",
    "        print(get_Qvalues([s],theta)[0])\n",
    "        a = np.argmax(get_Qvalues([s],theta)[0])\n",
    "        s1,r,done,_ = env.step(a)\n",
    "        if r == 0:\n",
    "            if done:\n",
    "                r = -0.2\n",
    "            else:\n",
    "                r = -0.01\n",
    "        else:\n",
    "            r = 1.0\n",
    "        #print(r)\n",
    "        total_reward += r\n",
    "        s = s1\n",
    "    env.render()\n",
    "    \n",
    "        \n",
    "    return obj, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5057327624974001\n",
      "0.4846988574193787\n",
      "0.4802209187756634\n",
      "0.5111933050689089\n",
      "0.47589843721606306\n",
      "0.4927097201728812\n",
      "0.47007923905524046\n",
      "0.5279355628371724\n",
      "0.49787213182006046\n",
      "0.464502390117824\n",
      "0.4915395542114574\n",
      "0.4757597348161143\n",
      "0.4691131231338712\n",
      "0.47506693782946524\n",
      "0.4843384016416108\n",
      "0.4657649574322455\n",
      "0.46504837647017533\n",
      "0.4622067069693727\n",
      "0.5239714597219643\n",
      "0.45907216282251156\n",
      "0.4551648307379938\n",
      "0.4198693114556648\n",
      "0.44792991281945077\n",
      "0.42648408420903877\n",
      "0.4234034177982347\n",
      "0.4383676878672051\n",
      "0.44617051557588505\n",
      "0.4390616709707707\n",
      "0.41710364326663657\n",
      "0.42196609710738375\n",
      "0.43793422670118537\n",
      "0.41773969996513044\n",
      "0.4132463094618907\n",
      "0.4119267236808042\n",
      "0.4491298321714972\n",
      "0.41208851784386075\n",
      "0.42654316347393056\n",
      "0.4089427913393017\n",
      "0.4154446342771223\n",
      "0.40632210851177075\n",
      "0.39932252463299944\n",
      "0.4004121127683246\n",
      "0.42542320210356516\n",
      "0.4190478543316752\n",
      "0.3804128304291168\n",
      "0.3695504666265251\n",
      "0.36844408458262895\n",
      "0.4225178208377576\n",
      "0.35723536830821284\n",
      "0.3613936093985333\n",
      "0.35326286501786713\n",
      "0.376824650707926\n",
      "0.3785463495548688\n",
      "0.362652157137183\n",
      "0.3605912462186221\n",
      "0.3961800132348041\n",
      "0.3519364211264883\n",
      "0.35223697635513157\n",
      "0.35631242675804975\n",
      "0.3368076482212216\n",
      "0.3414457789980411\n",
      "0.3419748725915784\n",
      "0.34371055160056185\n",
      "0.35745774880982434\n",
      "0.3279919465979962\n",
      "0.35308331515806607\n",
      "0.32955777346619913\n",
      "0.34904171987383936\n",
      "0.3417158622874294\n",
      "0.3338059526425991\n",
      "0.32804777396424023\n",
      "0.3552188818236348\n",
      "0.333696225046884\n",
      "0.3361100894184906\n",
      "0.32583368382797456\n",
      "0.3250667836029539\n",
      "0.3129308869145219\n",
      "0.3156953024875029\n",
      "0.32439610404713287\n",
      "0.33660712301590884\n",
      "0.3169548889170812\n",
      "0.30831946999187904\n",
      "0.31080702626525336\n",
      "0.30990789533280316\n",
      "0.31821232072775835\n",
      "0.2959803359980447\n",
      "0.29116967764717233\n",
      "0.2865761157497768\n",
      "0.29646189564175734\n",
      "0.29360056487078906\n",
      "0.2848351240874089\n",
      "0.2900799743883699\n",
      "0.2995948149591023\n",
      "0.28043701398131476\n",
      "0.29257670031313016\n",
      "0.29153847473192757\n",
      "0.2725744287616833\n",
      "0.2780520425045484\n",
      "0.27705896054212636\n",
      "0.28386145895827497\n",
      "0.27941761166251505\n",
      "0.26928950633379123\n",
      "0.2794748267953209\n",
      "0.27272345374274565\n",
      "0.26739425089826147\n",
      "0.27203062590613475\n",
      "0.2796652808883234\n",
      "0.2680893734960046\n",
      "0.2803111652788495\n",
      "0.2713972387375178\n",
      "0.2667691820441965\n",
      "0.2685628699202321\n",
      "0.2757137484340025\n",
      "0.270425076227\n",
      "0.2836554249456953\n",
      "0.2653115862634966\n",
      "0.2703867948272986\n",
      "0.2642439209586838\n",
      "0.2723938163469278\n",
      "0.2598180970912682\n",
      "0.26548946206250545\n",
      "0.26771471951270104\n",
      "0.26310522941357517\n",
      "0.2737613756866871\n",
      "0.2620718189395053\n",
      "0.2599615176720173\n",
      "0.26271261396081935\n",
      "0.25957662903623807\n",
      "0.26321556602990437\n",
      "0.26018953347221657\n",
      "0.2643362733837398\n",
      "0.25839530483660034\n",
      "0.2610081362106562\n",
      "0.2602495890825603\n",
      "0.2576396666424327\n",
      "0.25860702814688774\n",
      "0.2552352093789346\n",
      "0.25598076545193066\n",
      "0.2575382584422793\n",
      "0.25561483375415417\n",
      "0.2555475127928415\n",
      "0.25542697314665347\n",
      "0.2555938951111561\n",
      "0.26192970150883493\n",
      "0.2565486669346156\n",
      "0.2553930182361397\n",
      "0.2550797101812033\n",
      "0.25556777926483487\n",
      "0.25512641558277244\n",
      "0.2555183639872391\n",
      "0.25399750632430523\n",
      "0.25357400180974493\n",
      "0.25274925604921267\n",
      "0.25318803048201316\n",
      "0.2527976245903365\n",
      "0.2533913897116122\n",
      "0.25417472285143267\n",
      "0.2533578917701584\n",
      "0.2523829658250371\n",
      "0.2529123283150801\n",
      "0.2519429838964198\n",
      "0.2526332372954817\n",
      "0.2517983649123812\n",
      "0.25189819252718054\n",
      "0.25238757218264807\n",
      "0.25174778097184053\n",
      "0.25184800004812846\n",
      "0.2518982619973397\n",
      "0.2523361447240641\n",
      "0.25183840605980223\n",
      "0.25277781598762655\n",
      "0.2515557837986578\n",
      "0.25199019384162463\n",
      "0.2519346559574151\n",
      "0.2517205327632251\n",
      "0.2520390167059496\n",
      "0.2526188559715713\n",
      "0.2513954841578922\n",
      "0.2513797465481039\n",
      "0.252019665281005\n",
      "0.2522525942576718\n",
      "0.2513175487791319\n",
      "0.25106575926516966\n",
      "0.2516136901468992\n",
      "0.2515579183178194\n",
      "0.25158511614621865\n",
      "0.251051982862849\n",
      "0.2518586363736874\n",
      "0.25122357167793424\n",
      "0.2510355513354241\n",
      "0.2517693090577935\n",
      "0.25110153156250586\n",
      "0.25179066334280115\n",
      "0.2512740830050214\n",
      "0.2516747893513425\n",
      "0.25126634972539036\n",
      "0.25157189272299807\n",
      "0.2512875624741109\n",
      "0.25139518758902163\n",
      "0.2510207509711959\n",
      "0.2515256873476866\n",
      "0.2512506961394478\n",
      "0.2517659666465693\n",
      "0.2507594859349344\n",
      "0.251677609249712\n",
      "0.25102727069895703\n",
      "0.25158848402671824\n",
      "0.25090185621702527\n",
      "0.25067030125401774\n",
      "0.25087664056732556\n",
      "0.2505075259852146\n",
      "0.25062061379140604\n",
      "0.25057016939782223\n",
      "0.2506448466122651\n",
      "0.25064007069973454\n",
      "0.25070949512732776\n",
      "0.25048340180063156\n",
      "0.2504684408828415\n",
      "0.2504923347887186\n",
      "0.25057685531042767\n",
      "0.2505329894195969\n",
      "0.2505385266760028\n",
      "0.2506060659859274\n",
      "0.25050852599945667\n",
      "0.2505495044744131\n",
      "0.25068739478223284\n",
      "0.25047597316014003\n",
      "0.2505592255151292\n",
      "0.2505492097641236\n",
      "0.25044397431356696\n",
      "0.25039241164214093\n",
      "0.25042581544623826\n",
      "0.2503333745321558\n",
      "0.2503724306076413\n",
      "0.2503450954614692\n",
      "0.2503401023907657\n",
      "0.2504259624932574\n",
      "0.2503246251270787\n",
      "0.2503737296114405\n",
      "0.2503114905985639\n",
      "0.2502810517894014\n",
      "0.2502881527007071\n",
      "0.2502193572608979\n",
      "0.25024249929626663\n",
      "0.25024029238597606\n",
      "0.25022494377321264\n",
      "0.2502321914722911\n",
      "0.25020804211200315\n",
      "0.250229255707273\n",
      "0.250232202715359\n",
      "0.25028229336996016\n",
      "0.2502282915797069\n",
      "0.25022102124850215\n",
      "0.25022472858220873\n",
      "0.2502219175129724\n",
      "0.250212259981347\n",
      "0.25028733452450846\n",
      "0.25021751056922303\n",
      "0.25021364557984055\n",
      "0.25019522587486126\n",
      "0.25019208309913527\n",
      "0.2502118355057114\n",
      "0.2501954112315574\n",
      "0.25020509710208033\n",
      "0.25019691209371453\n",
      "0.25020066162451293\n",
      "0.2502011961372719\n",
      "0.25020313337091876\n",
      "0.2501996761329983\n",
      "0.25020028411823664\n",
      "0.25019748761248645\n",
      "0.2501753539809723\n",
      "0.25018728909130344\n",
      "0.25018185632244766\n",
      "0.25017760171847986\n",
      "0.2501810109284684\n",
      "0.2501766220122322\n",
      "0.2501781757744023\n",
      "0.25017115654541117\n",
      "0.2501758835036763\n",
      "0.25017049335505237\n",
      "0.25017335598964\n",
      "0.25016764150119547\n",
      "0.2501710178148506\n",
      "0.250167172321588\n",
      "0.2501686840702807\n",
      "0.2501626589976599\n",
      "0.2501672703437023\n",
      "0.2501653776471487\n",
      "0.250164684063654\n",
      "0.2501632208572126\n",
      "0.25016465442756747\n",
      "0.2501613791823914\n",
      "0.25016091423890546\n",
      "0.25015188557565965\n",
      "0.25014960986358864\n",
      "0.250150807073083\n",
      "0.25014428458169763\n",
      "0.2501486011284407\n",
      "0.2501420818717952\n",
      "0.2501379274357893\n",
      "0.25013672659821573\n",
      "0.2501394872831211\n",
      "0.2501370899074233\n",
      "0.25013542765290603\n",
      "0.25013252157334054\n",
      "0.250129794833912\n",
      "0.25012520267666066\n",
      "0.25012524159939425\n",
      "0.2501273510156363\n",
      "0.25012015460501097\n",
      "0.2501146185515178\n",
      "0.25011778940469226\n",
      "0.2501179646255198\n",
      "0.25011103635639814\n",
      "0.25011211121016463\n",
      "0.25011536079006347\n",
      "0.2501143796271991\n",
      "0.25011051656645567\n",
      "0.2501054615663523\n",
      "0.25010358825069795\n",
      "0.25010347846550135\n",
      "0.2501080972515848\n",
      "0.2501057306748506\n",
      "0.2501015153113329\n",
      "0.2501015224613868\n",
      "0.2501067765241024\n",
      "0.25009891445172466\n",
      "0.2500964395975759\n",
      "0.25009948089320877\n",
      "0.2500965204693959\n",
      "0.2500966726273262\n",
      "0.2500979784699931\n",
      "0.25009671225315616\n",
      "0.2500917794200483\n",
      "0.25009333481827506\n",
      "0.2500905142706538\n",
      "0.25009152029408294\n",
      "0.25009469352960717\n",
      "0.2500873367858752\n",
      "0.2500888860040869\n",
      "0.25008807720183096\n",
      "0.25008944806864886\n",
      "0.25008777443452995\n",
      "0.2500881573600134\n",
      "0.25008522046116827\n",
      "0.250088472022061\n",
      "0.2500878890169162\n",
      "0.2500866140266704\n",
      "0.2500864647786574\n",
      "0.25008845539336827\n",
      "0.2500811641370356\n",
      "0.2500835464085972\n",
      "0.25008203566472065\n",
      "0.2500815787880338\n",
      "0.250082267956272\n",
      "0.25008307922544754\n",
      "0.2500765179956293\n",
      "0.2500774730421907\n",
      "0.2500749519417275\n",
      "0.2500766494967957\n",
      "0.25007856122537403\n",
      "0.25007341363855057\n",
      "0.25007734085509087\n",
      "0.2500759863188579\n",
      "0.2500752232251208\n",
      "0.2500727276339859\n",
      "0.25007744590584086\n",
      "0.2500710728381506\n",
      "0.250067502102004\n",
      "0.2500695017755458\n",
      "0.2500656823865846\n",
      "0.2500674367608405\n",
      "0.2500668272264091\n",
      "0.2500643137359025\n",
      "0.2500653084275433\n",
      "0.2500634348463611\n",
      "0.2500643182788162\n",
      "0.25006261406729413\n",
      "0.2500670729375944\n",
      "0.250061116224948\n",
      "0.2500648258771699\n",
      "0.2500597384312545\n",
      "0.2500629136194508\n",
      "0.2500575758477843\n",
      "0.25005779267324774\n",
      "0.2500536203788135\n",
      "0.2500554818280675\n",
      "0.25005296633283297\n",
      "0.2500573233742352\n",
      "0.2500559453983023\n",
      "0.2500553077167638\n",
      "0.25005148095180996\n",
      "0.25005170607440436\n",
      "0.25005403217484184\n",
      "0.2500545020349414\n",
      "0.2500497168372428\n",
      "0.2500502495384096\n",
      "0.2500503069944984\n",
      "0.2500472079003058\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "0\n",
      "[1.42389308e-04 3.28332779e-01 3.28273963e-01 4.25186282e-05]\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "4\n",
      "[1.16441698e-03 1.88151766e-04 9.98599425e-01 4.18046409e-04]\n",
      "  (Right)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "total_rewards, theta = DQN(400,1e-1,0.99,0.9,env,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29564234505690196\n"
     ]
    }
   ],
   "source": [
    "print(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(get_Qvalues([0,1,2,6,10,14],theta),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(total_rewards,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - left\n",
    "\n",
    "1 - down\n",
    "\n",
    "2 - right\n",
    "\n",
    "3 - up\n",
    "\n",
    "0|1|2|3\n",
    "4|5|6|7\n",
    "8|9|10|11\n",
    "12|13|14|15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.0, False, {'prob': 1.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9405979999999999"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.01-0.01*0.99 - 0.99*0.99*0.01 + 0.99*0.99*0.99"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
