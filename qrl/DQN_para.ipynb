{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "#import pixiedust\n",
    "from gym.envs.registration import register\n",
    "from qiskit.aqua.components.optimizers import ADAM\n",
    "from qiskit import *\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AccountProvider for IBMQ(hub='ibm-q', group='open', project='main')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "register(\n",
    "    id='FrozenLakeNotSlippery-v0',\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name' : '4x4', 'is_slippery': False},\n",
    "    max_episode_steps=100,\n",
    "    reward_threshold=0.8196, # optimum = .8196, changing this seems have no influence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLakeNotSlippery-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numStates(env):\n",
    "    if type(env.observation_space) != gym.spaces.tuple.Tuple:\n",
    "        return env.observation_space.n\n",
    "    dim_list = []\n",
    "    for sp in env.observation_space:\n",
    "        dim_list.append(sp.n)\n",
    "    dim_list = np.array(dim_list)\n",
    "    return dim_list.prod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Statehash(env,state):\n",
    "    if type(env.observation_space) != gym.spaces.tuple.Tuple:\n",
    "        return state\n",
    "    dim_list = []\n",
    "    for sp in env.observation_space:\n",
    "        dim_list.append(sp.n)\n",
    "    dim_list = np.array(dim_list)\n",
    "    h = 0\n",
    "    for i in range(len(dim_list)-1):\n",
    "        h += state[i]*dim_list[i+1:].prod()\n",
    "    h += state[-1]\n",
    "    return h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QLearning(iterations,alpha, gamma, epsilon ,env):\n",
    "    returnlist = []\n",
    "    num_actions = env.action_space.n\n",
    "    num_states = get_numStates(env)\n",
    "    Q = np.zeros((num_states,num_actions))\n",
    "    for it in range(iterations):\n",
    "        state = env.reset()\n",
    "        R = 0\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            state_h = get_Statehash(env,state)\n",
    "            if np.random.random() < epsilon:\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                candidates = np.where(Q[state_h] == np.max(Q[state_h]))[0]\n",
    "                action = np.random.choice(candidates)\n",
    "            statep, reward, done, info = env.step(action)\n",
    "            if reward == 0:\n",
    "                if done:\n",
    "                    reward = -0.2\n",
    "                else:\n",
    "                    reward = -0.01\n",
    "            else:\n",
    "                reward = 1.0\n",
    "            R *= gamma\n",
    "            R += reward\n",
    "            statep_h = get_Statehash(env,statep)\n",
    "            Q[state_h,action] += alpha*(reward + gamma*Q[statep_h].max() -Q[state_h,action])\n",
    "            state = statep\n",
    "            \n",
    "        returnlist.append(R)\n",
    "        if it%10000 == 0:\n",
    "            print('Iteration %d, Reward: %d'%(it,R))\n",
    "            \n",
    "    return returnlist, Q\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl, Q = QLearning(100000,1e-3,0.99,0.25,env)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     backend_sim = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "#     result = execute(qc, backend_sim, shots = shots).result()\n",
    "\n",
    "#     counts = result.get_counts()\n",
    "#     expect = np.zeros(nqbits)\n",
    "#     for c in counts :\n",
    "#         for n in range(nqbits):\n",
    "#             expect[n] += int(c[n])*counts[c]/shots\n",
    "#     #print(counts)\n",
    "#     return np.array(expect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Qvalues(s_list,theta):\n",
    "    shots = 1000\n",
    "    nqbits = 4\n",
    "    num_rep = 1\n",
    "    qc_list = []\n",
    "    for s in s_list:\n",
    "        q = QuantumRegister(nqbits)\n",
    "        c = ClassicalRegister(nqbits)\n",
    "        qc = QuantumCircuit(q,c)\n",
    "\n",
    "        d = np.binary_repr(int(s),nqbits)\n",
    "        for j,i in enumerate(d):\n",
    "            if i == '1':\n",
    "                qc.x(q[j])\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for rep in range(num_rep):\n",
    "            for i in range(1, nqbits):\n",
    "                qc.cx(q[i-1], q[i])\n",
    "\n",
    "            for i in range(nqbits):\n",
    "                qc.u3(theta[count], theta[count + 1], theta[count + 2], q[i])\n",
    "                count = count + 3\n",
    "\n",
    "        #qc.measure(q,c)\n",
    "        \n",
    "        qc_list.append(qc)\n",
    "\n",
    "\n",
    "    \n",
    "    backend_sim = Aer.get_backend('statevector_simulator')\n",
    "    qobj = assemble(qc_list,backend_sim)\n",
    "    #result_list = execute(qc_list, backend_sim, optimization_level = 0).result()\n",
    "    job = backend_sim.run(qobj)\n",
    "    result_list = job.result()\n",
    "    expect_list = []\n",
    "    for result in result_list.results:\n",
    "        proba = abs(np.array(result.data.statevector))**2\n",
    "\n",
    "\n",
    "        expect = np.zeros(nqbits)\n",
    "\n",
    "        for c in range(len(proba)):\n",
    "            cbin = np.binary_repr(int(c),nqbits)\n",
    "\n",
    "            for n in range(nqbits) : \n",
    "                if cbin[n] == '1':\n",
    "                    expect[n] += proba[c]\n",
    "                    \n",
    "        expect_list.append(np.flip(expect))\n",
    "                \n",
    "    #print(counts)\n",
    "    return expect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(theta, t):\n",
    "    su = 0\n",
    "    Qs = get_Qvalues(t[:,1],theta)\n",
    "    \n",
    "    for i in range(len(t)):\n",
    "        su += (t[i][0] - Qs[i][int(t[i][2])])**2\n",
    "    return su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(iterations,alpha, gamma, epsilon ,env,N,batchsize):\n",
    "    nqbits = 4\n",
    "    D = []\n",
    "    while len(D) < N:\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            a = env.action_space.sample()\n",
    "            s1, r, done,_ = env.step(a)\n",
    "            if r == 0:\n",
    "                if done:\n",
    "                    r = -0.2\n",
    "                else:\n",
    "                    r = -0.01\n",
    "            else:\n",
    "                r = 1.0\n",
    "            D.append((s,a,r,s1,done))\n",
    "            s = s1\n",
    "            if len(D) == N:\n",
    "                break\n",
    "    total_rewards = []\n",
    "    theta = np.array([2*np.pi*np.random.random(3),2*np.pi*np.random.random(3),2*np.pi*np.random.random(3),2*np.pi*np.random.random(3)]).flatten()\n",
    "    for it in range(iterations):\n",
    "        s = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            #env.render()\n",
    "            if np.random.random() < epsilon*(0.99**it):\n",
    "                a = env.action_space.sample()\n",
    "            else:\n",
    "                a = np.argmax(get_Qvalues([s],theta)[0])\n",
    "            s1,r,done,_ = env.step(a)\n",
    "            if r == 0:\n",
    "                if done:\n",
    "                    r = -0.2\n",
    "                else:\n",
    "                    r = -0.01\n",
    "            else:\n",
    "                r = 1.0\n",
    "            #print(r)\n",
    "            total_reward += r\n",
    "            D.pop(0)\n",
    "            D.append((s,a,r,s1,done))\n",
    "        mB_ind = np.random.choice(range(N),size = batchsize,replace = False)\n",
    "        mB = np.array(D)[mB_ind]\n",
    "        #update Q on mB\n",
    "        t = []\n",
    "        for j in range(batchsize):\n",
    "            if mB[j][-1]:\n",
    "                y_j = mB[j][2]\n",
    "            else:\n",
    "                y_j = mB[j][2] + gamma*(2*max(get_Qvalues([mB[j][3]],theta)[0])-1)\n",
    "            y_j /= 2\n",
    "            y_j += 0.5\n",
    "            t.append([y_j,mB[j][0],mB[j][1]])\n",
    "\n",
    "        t = np.array(t)\n",
    "\n",
    "        adam = ADAM(maxiter = 10, lr = alpha)\n",
    "        start = datetime.now()\n",
    "        print(theta)\n",
    "        theta,_,_ = adam.optimize(3*nqbits,lambda x: loss(x,t), initial_point = theta)\n",
    "        print(datetime.now()-start)\n",
    "        if it %1 == 0:\n",
    "            print('Iteration : ', it, 'Total reward: ', total_reward)\n",
    "        total_rewards.append(total_reward)\n",
    "        \n",
    "    return total_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "0.855\n",
      "0.81225\n",
      "0.7716374999999999\n",
      "0.7330556249999999\n",
      "0.6964028437499998\n",
      "0.6615827015624999\n",
      "0.6285035664843748\n",
      "0.597078388160156\n",
      "0.5672244687521482\n",
      "0.5388632453145408\n",
      "0.5119200830488138\n",
      "0.486324078896373\n",
      "0.4620078749515543\n",
      "0.4389074812039766\n",
      "0.41696210714377774\n",
      "0.39611400178658884\n",
      "0.3763083016972594\n",
      "0.35749288661239637\n",
      "0.33961824228177656\n",
      "0.3226373301676877\n",
      "0.30650546365930337\n",
      "0.29118019047633814\n",
      "0.27662118095252125\n",
      "0.26279012190489515\n",
      "0.2496506158096504\n",
      "0.23716808501916783\n",
      "0.22530968076820942\n",
      "0.21404419672979894\n",
      "0.20334198689330898\n",
      "0.19317488754864354\n",
      "0.18351614317121134\n",
      "0.17434033601265078\n",
      "0.16562331921201826\n",
      "0.15734215325141732\n",
      "0.14947504558884644\n",
      "0.14200129330940411\n",
      "0.13490122864393392\n",
      "0.1281561672117372\n",
      "0.12174835885115033\n",
      "0.11566094090859282\n",
      "0.10987789386316317\n",
      "0.104383999170005\n",
      "0.09916479921150476\n",
      "0.09420655925092951\n",
      "0.08949623128838302\n",
      "0.08502141972396388\n",
      "0.08077034873776569\n",
      "0.07673183130087738\n",
      "0.07289523973583352\n"
     ]
    }
   ],
   "source": [
    "for it in range(50):\n",
    "    print(0.9*(0.95**it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73382753 0.79757302 5.2339608  2.42235478 2.96652883 2.48884058\n",
      " 1.91673216 3.6061689  3.38333838 3.43574185 5.26956836 5.95155978]\n",
      "0:00:04.128194\n",
      "Iteration :  0 Total reward:  -0.32999999999999996\n",
      "[1.64822148 0.26801752 4.82763436 1.45398025 3.24276794 2.59214689\n",
      " 1.99401989 3.55141027 3.7456713  3.51173815 5.19115819 6.43248644]\n",
      "0:00:04.149396\n",
      "Iteration :  1 Total reward:  -0.32\n",
      "[1.73288994 0.41904597 5.41863689 1.40450943 3.08549373 3.02804377\n",
      " 1.53458682 3.5608932  4.02176206 4.51850665 5.56325589 6.64851843]\n",
      "0:00:04.191986\n",
      "Iteration :  2 Total reward:  -0.21000000000000002\n",
      "[1.78096661 0.61861777 5.22062657 1.77084372 3.68964352 3.51124205\n",
      " 1.71887282 3.15025581 3.96441381 4.82536856 5.41572358 6.86340739]\n",
      "0:00:04.194157\n",
      "Iteration :  3 Total reward:  -0.38\n",
      "[1.70386966 0.47589427 4.93911704 1.36447508 3.25718974 2.93980857\n",
      " 1.62073481 2.95191239 3.59502817 4.75539108 5.46002474 7.06448982]\n",
      "0:00:04.121441\n",
      "Iteration :  4 Total reward:  -0.21000000000000002\n",
      "[1.65198411 0.61919822 4.4396106  1.6899831  2.76254681 2.48635635\n",
      " 1.71833093 3.2271408  3.88611153 4.65238568 5.51996498 6.93567469]\n",
      "0:00:04.350584\n",
      "Iteration :  5 Total reward:  -0.21000000000000002\n",
      "[1.7035143  0.61933066 4.24426233 1.7388187  3.05460437 2.5366533\n",
      " 1.66863612 2.90921969 3.58405274 4.70249892 5.52430048 6.91493095]\n",
      "0:00:04.366001\n",
      "Iteration :  6 Total reward:  -0.26\n",
      "[1.65250534 0.58479216 4.84416809 1.68595055 3.17958194 3.0187219\n",
      " 2.25766914 2.66680637 4.10944345 4.79594845 5.36693214 7.09707877]\n",
      "0:00:04.214750\n",
      "Iteration :  7 Total reward:  -0.38\n",
      "[2.10005691 0.50933279 4.51810851 1.56177395 3.25139053 2.94654543\n",
      " 1.62889847 2.67359906 3.75216593 3.93909005 5.19037147 7.09707877]\n",
      "0:00:04.083969\n",
      "Iteration :  8 Total reward:  -0.29000000000000004\n",
      "[2.04638623 0.74433914 4.9603008  2.35060778 2.93453049 2.94654543\n",
      " 1.77022802 3.12787262 3.75216593 4.59664637 5.28519201 6.85071392]\n",
      "0:00:04.073759\n",
      "Iteration :  9 Total reward:  -0.27\n",
      "[2.46005396 0.63246205 4.9603008  1.97387017 3.30734912 2.94654543\n",
      " 2.53014151 2.93209494 3.75216593 3.7901213  5.87147525 6.85071392]\n",
      "0:00:03.886762\n",
      "Iteration :  10 Total reward:  -0.32\n",
      "[2.52191146 0.35592009 4.9603008  2.67712015 3.34731681 2.94654543\n",
      " 2.47493319 2.68491912 3.75216593 3.84896341 5.82515189 6.85071392]\n",
      "0:00:03.972297\n",
      "Iteration :  11 Total reward:  -0.23\n",
      "[2.57872085 0.7978469  4.9603008  1.66942928 2.93294875 2.94654543\n",
      " 1.71686404 3.21735838 3.75216593 3.56481235 5.31386949 6.85071392]\n",
      "0:00:03.996696\n",
      "Iteration :  12 Total reward:  -0.25\n",
      "[2.62359184 1.16079934 4.9603008  1.99556671 3.00265268 2.94654543\n",
      " 1.83780897 3.32603146 3.75216593 3.67143157 5.84656423 6.85071392]\n",
      "0:00:04.138712\n",
      "Iteration :  13 Total reward:  -0.27\n",
      "[2.56761821 1.07811818 4.9603008  2.76416924 2.54128602 2.94654543\n",
      " 2.66870289 3.49195935 3.75216593 3.72981868 5.30267677 6.85071392]\n",
      "0:00:03.890396\n",
      "Iteration :  14 Total reward:  -0.23\n",
      "[2.70410275 0.78878023 4.9603008  2.64907022 2.84041492 2.94654543\n",
      " 2.24700731 3.48658151 3.75216593 3.54564242 5.37300357 6.85071392]\n",
      "0:00:03.895608\n",
      "Iteration :  15 Total reward:  -0.21000000000000002\n",
      "[2.64292354 1.00903787 4.9603008  2.72018641 3.19439103 2.94654543\n",
      " 2.16425788 3.74100849 3.75216593 3.61450781 5.41791296 6.85071392]\n",
      "0:00:03.959188\n",
      "Iteration :  16 Total reward:  -0.22\n",
      "[2.67832556 0.72786033 4.9603008  1.71783027 3.6267982  2.94654543\n",
      " 1.9420619  4.14221932 3.75216593 3.58038945 5.91012282 6.85071392]\n",
      "0:00:03.911412\n",
      "Iteration :  17 Total reward:  -0.43000000000000005\n",
      "[2.6167549  0.23507945 4.9603008  1.94801538 3.41933075 2.94654543\n",
      " 2.75570848 3.68285301 3.75216593 3.64711635 5.42689887 6.85071392]\n",
      "0:00:03.914275\n",
      "Iteration :  18 Total reward:  -0.21000000000000002\n",
      "[1.72582561 0.87900067 4.9603008  1.86922462 3.37573225 2.94654543\n",
      " 2.10268211 3.31946269 3.75216593 3.56752171 5.71857809 6.85071392]\n",
      "0:00:03.900352\n",
      "Iteration :  19 Total reward:  -0.37\n",
      "[1.67383048 1.61594435 4.9603008  1.29006562 3.21914843 2.94654543\n",
      " 2.0489939  3.45576201 3.75216593 4.37109821 5.21348838 6.85071392]\n",
      "0:00:03.890914\n",
      "Iteration :  20 Total reward:  -0.21000000000000002\n",
      "[2.07085549 2.19201511 4.9603008  1.84839233 3.48158004 2.94654543\n",
      " 1.99552624 2.90801377 3.75216593 4.30372476 5.53135744 6.85071392]\n",
      "0:00:03.903977\n",
      "Iteration :  21 Total reward:  -0.23\n",
      "[2.01730035 2.00957645 4.9603008  1.1158268  3.30404499 2.94654543\n",
      " 2.08615932 2.83754773 3.75216593 4.21001153 5.31905115 6.85071392]\n",
      "0:00:03.868079\n",
      "Iteration :  22 Total reward:  -0.21000000000000002\n",
      "[2.06768207 1.58579961 4.9603008  1.77509238 3.66226827 2.94654543\n",
      " 2.03431594 2.30636218 3.75216593 4.26496752 4.88962631 6.85071392]\n",
      "0:00:03.911216\n",
      "Iteration :  23 Total reward:  -0.21000000000000002\n",
      "[2.01413514 1.3175485  4.9603008  2.14418328 3.11753997 2.94654543\n",
      " 2.08035342 1.9831126  3.75216593 4.34794113 4.68982578 6.85071392]\n",
      "0:00:03.877787\n",
      "Iteration :  24 Total reward:  -0.22\n",
      "[1.69427877 1.85958651 4.9603008  1.48802159 3.53843641 2.94654543\n",
      " 1.98730311 2.38041906 3.75216593 4.17787848 5.00431438 6.85071392]\n",
      "0:00:03.890129\n",
      "Iteration :  25 Total reward:  -0.42000000000000004\n",
      "[1.90723905 2.02352954 4.9603008  1.41713004 3.24959654 2.94654543\n",
      " 1.53418613 2.29407341 3.75216593 4.26346088 4.80024556 6.85071392]\n",
      "0:00:04.054625\n",
      "Iteration :  26 Total reward:  -0.31\n",
      "[1.94734355 2.40886235 4.9603008  1.49066483 3.69483796 2.94654543\n",
      " 2.05543343 2.66803611 3.75216593 4.35865626 4.60521896 6.85071392]\n",
      "0:00:03.999027\n",
      "Iteration :  27 Total reward:  -0.28\n",
      "[1.89431138 2.16910247 4.9603008  1.58348217 3.82691877 2.94654543\n",
      " 2.00193825 2.47951975 3.75216593 4.27399968 4.64612562 6.85071392]\n",
      "0:00:03.969666\n",
      "Iteration :  28 Total reward:  -0.25\n",
      "[1.84151939 2.02923446 4.9603008  1.38206618 3.68068491 2.94654543\n",
      " 1.94739367 2.84827473 3.75216593 4.32686    4.77389362 6.85071392]\n",
      "0:00:04.120086\n",
      "Iteration :  29 Total reward:  -0.31\n",
      "[1.93777046 1.88881622 4.9603008  1.27440721 3.18195142 2.94654543\n",
      " 1.89436171 2.79364083 3.75216593 4.3793979  4.36265871 6.85071392]\n",
      "0:00:03.954632\n",
      "Iteration :  30 Total reward:  -0.23\n",
      "[1.8847802  1.25518029 4.9603008  1.36231229 2.89638239 2.94654543\n",
      " 1.94302203 2.54264301 3.75216593 4.33253667 4.24609061 6.85071392]\n",
      "0:00:03.993979\n",
      "Iteration :  31 Total reward:  -0.4700000000000001\n",
      "[1.95042147 1.18688513 4.9603008  1.64379823 2.81743905 2.94654543\n",
      " 1.89000832 2.82427982 3.75216593 4.3835669  4.49442808 6.85071392]\n",
      "0:00:04.014787\n",
      "Iteration :  32 Total reward:  -0.32\n",
      "[1.89737589 1.82059527 4.9603008  1.30416478 2.62407054 2.94654543\n",
      " 1.95931095 2.78070017 3.75216593 4.32894192 4.71653469 6.85071392]\n",
      "0:00:03.963259\n",
      "Iteration :  33 Total reward:  -0.21000000000000002\n",
      "[1.96923953 2.02599574 4.9603008  1.41758391 3.27552858 2.94654543\n",
      " 1.90564975 3.1318762  3.75216593 4.38017458 4.60841401 6.85071392]\n",
      "0:00:04.000496\n",
      "Iteration :  34 Total reward:  -0.28\n",
      "[1.91611054 2.36817583 4.9603008  1.857508   3.13149492 2.94654543\n",
      " 1.85342556 3.74963668 3.75216593 4.30075191 5.07083268 6.85071392]\n",
      "0:00:04.115540\n",
      "Iteration :  35 Total reward:  -0.3\n",
      "[1.552135   2.14481659 4.9603008  1.64927969 3.45444077 2.94654543\n",
      " 1.92762062 3.912485   3.75216593 4.38198443 5.2964995  6.85071392]\n",
      "0:00:04.395962\n",
      "Iteration :  36 Total reward:  -0.26\n",
      "[2.07875467 2.58341845 4.9603008  1.29743848 3.63684245 2.94654543\n",
      " 1.87656683 4.5223099  3.75216593 4.33388521 5.71529096 6.85071392]\n",
      "0:00:04.127857\n",
      "Iteration :  37 Total reward:  -0.29000000000000004\n",
      "[2.02516222 2.7025072  4.9603008  1.43414156 3.3992484  2.94654543\n",
      " 1.95524781 4.61413552 3.75216593 4.2662172  6.18118524 6.85071392]\n",
      "0:00:03.994989\n",
      "Iteration :  38 Total reward:  -0.24000000000000002\n",
      "[1.9717933  3.14724043 4.9603008  1.33839688 3.72219729 2.94654543\n",
      " 1.85112955 4.14995143 3.75216593 4.32091865 6.73532916 6.85071392]\n",
      "0:00:03.933054\n",
      "Iteration :  39 Total reward:  -0.33999999999999997\n",
      "[1.91865663 2.77133567 4.9603008  1.38955546 3.54412501 2.94654543\n",
      " 1.92332419 4.17593115 3.75216593 4.37530571 6.58039256 6.85071392]\n",
      "0:00:03.952794\n",
      "Iteration :  40 Total reward:  -0.22\n",
      "[1.8648662  2.62740224 4.9603008  1.65207735 3.41419464 2.94654543\n",
      " 1.87039888 4.18789799 3.75216593 4.32549017 6.34681242 6.85071392]\n",
      "0:00:03.895342\n",
      "Iteration :  41 Total reward:  -0.37\n",
      "[1.93674034 2.59206935 4.9603008  2.13317253 3.85279277 2.94654543\n",
      " 1.63176819 4.54573846 3.75216593 4.37856806 6.19830002 6.85071392]\n",
      "0:00:04.002326\n",
      "Iteration :  42 Total reward:  -0.22\n",
      "[2.07806911 2.88548806 4.9603008  1.44368336 3.82768196 2.94654543\n",
      " 1.85517312 4.30155229 3.75216593 4.16091709 6.68588786 6.85071392]\n",
      "0:00:03.957696\n",
      "Iteration :  43 Total reward:  -0.28\n",
      "[2.12383822 2.48732436 4.9603008  2.24823522 3.52571132 2.94654543\n",
      " 2.1676745  3.75255491 3.75216593 4.21468735 6.38142965 6.85071392]\n",
      "0:00:03.991950\n",
      "Iteration :  44 Total reward:  -0.25\n",
      "[1.75845228 2.18597682 4.9603008  2.16508965 3.32294795 2.94654543\n",
      " 1.63551955 3.50106405 3.75216593 4.10755051 5.81331183 6.85071392]\n",
      "0:00:03.965203\n",
      "Iteration :  45 Total reward:  -0.8400000000000003\n",
      "[2.36183583 2.27165236 4.9603008  1.8159456  2.86991023 2.94654543\n",
      " 2.36859257 3.84021625 3.75216593 4.15988922 5.40117581 6.85071392]\n",
      "0:00:03.990429\n",
      "Iteration :  46 Total reward:  -0.21000000000000002\n",
      "[2.30722896 2.23200968 4.9603008  1.89227355 3.28540554 2.94654543\n",
      " 2.31394909 4.28208243 3.75216593 3.89492869 5.60639974 6.85071392]\n",
      "0:00:04.039442\n",
      "Iteration :  47 Total reward:  -0.31\n",
      "[2.39591264 2.51579275 4.9603008  1.70077518 2.91144423 2.94654543\n",
      " 2.75215891 4.64655903 3.75216593 3.99028763 5.95817067 6.85071392]\n",
      "0:00:04.168705\n",
      "Iteration :  48 Total reward:  -0.23\n",
      "[2.93375739 2.09193747 4.9603008  1.24125459 2.22954795 2.94654543\n",
      " 2.31508743 4.11902314 3.75216593 3.91719112 5.32665417 6.85071392]\n",
      "0:00:04.367412\n",
      "Iteration :  49 Total reward:  -0.25\n",
      "[2.92222531 1.73570458 4.9603008  1.24900164 2.42024637 2.94654543\n",
      " 3.0360848  4.31164913 3.75216593 3.22111784 5.60681931 6.85071392]\n",
      "0:00:04.448819\n",
      "Iteration :  50 Total reward:  -0.32999999999999996\n",
      "[1.93444264 2.21808022 4.9603008  2.06605024 2.3027097  2.94654543\n",
      " 2.91967539 5.01857986 3.75216593 3.38930083 5.05010864 6.85071392]\n",
      "0:00:04.015579\n",
      "Iteration :  51 Total reward:  -0.21000000000000002\n",
      "[1.876245   2.73226858 4.9603008  2.16605049 2.80137665 2.94654543\n",
      " 1.93621677 5.7651018  3.75216593 4.14286726 5.55887724 6.85071392]\n",
      "0:00:03.937137\n",
      "Iteration :  52 Total reward:  -0.21000000000000002\n",
      "[2.24500054 2.81660388 4.9603008  2.10425604 3.1064977  2.94654543\n",
      " 2.14181248 6.30845756 3.75216593 4.09615044 6.1385336  6.85071392]\n",
      "0:00:03.932550\n",
      "Iteration :  53 Total reward:  -0.36\n",
      "[2.172304   3.02840768 4.9603008  1.75278919 3.46437658 2.94654543\n",
      " 2.22691373 6.40853329 3.75216593 4.03910544 5.74016489 6.85071392]\n",
      "0:00:03.889903\n",
      "Iteration :  54 Total reward:  -0.33999999999999997\n",
      "[2.25339298 3.08382576 4.9603008  2.35929749 3.00269352 2.94654543\n",
      " 2.12519048 6.409276   3.75216593 4.09195114 5.54744605 6.85071392]\n",
      "0:00:04.034489\n",
      "Iteration :  55 Total reward:  -0.22\n",
      "[1.95912319 2.75696877 4.9603008  1.40477023 2.92652015 2.94654543\n",
      " 2.22368668 6.37267036 3.75216593 4.0065339  5.63943717 6.85071392]\n",
      "0:00:04.399340\n",
      "Iteration :  56 Total reward:  -0.22\n",
      "[1.64403086 2.86387155 4.9603008  1.67660777 2.36802218 2.94654543\n",
      " 2.1424701  6.57061652 3.75216593 4.06271377 5.57014365 6.85071392]\n",
      "0:00:03.973833\n",
      "Iteration :  57 Total reward:  -0.41000000000000003\n",
      "[2.40623983 2.73535612 4.9603008  1.61342776 2.27689698 2.94654543\n",
      " 1.91825096 6.11095501 3.75216593 4.11685391 5.34455613 6.85071392]\n",
      "0:00:03.936868\n",
      "Iteration :  58 Total reward:  -0.23\n",
      "[2.35148265 3.403042   4.9603008  2.46670682 2.72722861 2.94654543\n",
      " 2.60532503 6.05742688 3.75216593 3.85814835 5.85764088 6.85071392]\n",
      "0:00:04.056581\n",
      "Iteration :  59 Total reward:  -0.25\n",
      "[2.66142729 3.42773818 4.9603008  1.49268607 2.77479832 2.94654543\n",
      " 1.98340545 6.29744517 3.75216593 3.75728494 5.67118932 6.85071392]\n",
      "0:00:03.980114\n",
      "Iteration :  60 Total reward:  -0.5200000000000001\n",
      "[1.72121026 2.79843914 4.9603008  1.58466503 2.05042155 2.94654543\n",
      " 2.77074818 6.15739682 3.75216593 3.69906456 5.40982575 6.85071392]\n",
      "0:00:03.880941\n",
      "Iteration :  61 Total reward:  -0.32\n",
      "[1.63393773 2.87143072 4.9603008  1.95156492 2.13280055 2.94654543\n",
      " 2.15292843 6.35732075 3.75216593 4.50228742 5.90029257 6.85071392]\n",
      "0:00:04.036791\n",
      "Iteration :  62 Total reward:  -0.21000000000000002\n",
      "[1.70789343 3.19690071 4.9603008  1.22420665 2.59072499 2.94654543\n",
      " 2.07232459 6.46991753 3.75216593 3.96967502 5.63155467 6.85071392]\n",
      "0:00:04.379514\n",
      "Iteration :  63 Total reward:  -0.26\n",
      "[2.04841836 3.04511268 4.9603008  1.51121529 2.91533092 2.94654543\n",
      " 2.1465693  6.40674281 3.75216593 4.43151952 5.6304775  6.85071392]\n",
      "0:00:03.940348\n",
      "Iteration :  64 Total reward:  -0.22\n",
      "[1.97052394 3.42898789 4.9603008  2.12057978 2.84978019 2.94654543\n",
      " 2.09270186 6.46980409 3.75216593 4.05235613 5.71266872 6.85071392]\n",
      "0:00:03.896902\n",
      "Iteration :  65 Total reward:  -0.4800000000000001\n",
      "[1.16853725 3.69116707 4.9603008  2.06086794 2.84818974 2.94654543\n",
      " 1.96968831 6.64432266 3.75216593 4.13325734 5.65573322 6.85071392]\n",
      "0:00:03.938873\n",
      "Iteration :  66 Total reward:  -0.28\n",
      "[1.98609863 3.39560607 4.9603008  1.20537276 2.81556316 2.94654543\n",
      " 2.07838334 6.73235506 3.75216593 4.88842686 5.46475093 6.85071392]\n",
      "0:00:03.943815\n",
      "Iteration :  67 Total reward:  -0.42000000000000004\n",
      "[1.89036333 3.02649751 4.9603008  1.70514369 2.93650747 2.94654543\n",
      " 1.97797608 6.79438805 3.75216593 4.05719619 5.24085301 6.85071392]\n",
      "0:00:03.898603\n",
      "Iteration :  68 Total reward:  -0.5500000000000002\n",
      "[1.97309715 2.7919015  4.9603008  1.80015398 3.11274674 2.94654543\n",
      " 2.24863857 7.27786268 3.75216593 4.14351683 4.74661301 6.85071392]\n",
      "0:00:03.935922\n",
      "Iteration :  69 Total reward:  -0.33999999999999997\n",
      "[2.30037648 3.02624008 4.9603008  2.21024117 2.74914448 2.94654543\n",
      " 2.16734006 7.60048801 3.75216593 4.19851365 4.42663034 6.85071392]\n",
      "0:00:03.899692\n",
      "Iteration :  70 Total reward:  -0.42000000000000004\n",
      "[2.24595872 3.44154688 4.9603008  2.55496306 2.71316442 2.94654543\n",
      " 2.23125408 7.33722529 3.75216593 4.00818653 3.96189645 6.85071392]\n",
      "0:00:03.932998\n",
      "Iteration :  71 Total reward:  -0.22\n",
      "[2.68593003 3.7650531  4.9603008  1.56853036 2.44037965 2.94654543\n",
      " 2.70115742 7.3408873  3.75216593 3.63449058 3.26654673 6.85071392]\n",
      "0:00:03.884092\n",
      "Iteration :  72 Total reward:  -0.32\n",
      "[2.62931656 3.76448914 4.9603008  2.47143139 2.32059356 2.94654543\n",
      " 2.63741689 7.55876789 3.75216593 3.68979012 2.95414665 6.85071392]\n",
      "0:00:03.944839\n",
      "Iteration :  73 Total reward:  -0.5200000000000001\n",
      "[2.57326454 4.18626599 4.9603008  1.49667067 2.07653984 2.94654543\n",
      " 2.5776016  7.25017909 3.75216593 3.65155787 3.04070419 6.85071392]\n",
      "0:00:03.944326\n",
      "Iteration :  74 Total reward:  -0.27\n",
      "[2.61308338 4.00716994 4.9603008  2.40813589 2.43859472 2.94654543\n",
      " 2.61557782 7.50036178 3.75216593 3.70763588 2.90635074 6.85071392]\n",
      "0:00:03.906808\n",
      "Iteration :  75 Total reward:  -0.37\n",
      "[2.55723297 4.53950512 4.9603008  1.44407108 3.00694572 2.94654543\n",
      " 2.55946355 8.25078476 3.75216593 3.66900297 3.19092036 6.85071392]\n",
      "0:00:03.948790\n",
      "Iteration :  76 Total reward:  -0.21000000000000002\n",
      "[2.90418745 4.37028601 4.9603008  1.24829392 3.11261174 2.94654543\n",
      " 2.59928397 8.12096367 3.75216593 3.72485895 2.88147992 6.85071392]\n",
      "0:00:03.944499\n",
      "Iteration :  77 Total reward:  -1.1600000000000006\n",
      "[2.80645462 3.87961528 4.9603008  2.20232106 3.10622597 2.94654543\n",
      " 3.05778174 8.31982372 3.75216593 3.2009921  3.1183346  6.85071392]\n",
      "0:00:03.905877\n",
      "Iteration :  78 Total reward:  -0.23\n",
      "[2.84966085 3.74769992 4.9603008  2.93858007 2.96408922 2.94654543\n",
      " 3.31738538 8.7127615  3.75216593 3.37351319 2.98701859 6.85071392]\n",
      "0:00:04.329309\n",
      "Iteration :  79 Total reward:  -0.36\n",
      "[2.80238948 3.84577042 4.9603008  1.93377266 2.98876299 2.94654543\n",
      " 3.43686643 9.27449271 3.75216593 3.43265838 2.73990265 6.85071392]\n",
      "0:00:04.259626\n",
      "Iteration :  80 Total reward:  -0.43000000000000005\n",
      "[2.74160322 4.21532845 4.9603008  1.06675065 2.57518802 2.94654543\n",
      " 3.54001696 9.2455915  3.75216593 3.51153892 2.60254972 6.85071392]\n",
      "0:00:04.104485\n",
      "Iteration :  81 Total reward:  -0.7100000000000002\n",
      "[2.68331129 4.7773002  4.9603008  2.0366996  2.95712753 2.94654543\n",
      " 3.59724729 9.57145299 3.75216593 3.58410523 2.80196484 6.85071392]\n",
      "0:00:03.916240\n",
      "Iteration :  82 Total reward:  -0.7300000000000002\n",
      "[2.62609082 5.06879379 4.9603008  2.41125073 3.23769158 2.94654543\n",
      " 3.65398342 9.87995362 3.75216593 3.64433252 3.14001491 6.85071392]\n",
      "0:00:03.938551\n",
      "Iteration :  83 Total reward:  -0.5200000000000001\n",
      "[ 2.56899765  5.1523037   4.9603008   2.6470463   3.51246722  2.94654543\n",
      "  3.9727226  10.07518493  3.75216593  3.70088578  3.25914652  6.85071392]\n",
      "0:00:03.954423\n",
      "Iteration :  84 Total reward:  -0.22\n",
      "[ 2.6337602   5.54918592  4.9603008   2.82387482  3.83286197  2.94654543\n",
      "  3.47203312 10.42495458  3.75216593  3.6569034   3.20547129  6.85071392]\n",
      "0:00:04.210116\n",
      "Iteration :  85 Total reward:  -0.21000000000000002\n",
      "[ 2.74162898  5.40556683  4.9603008   2.52685045  3.72705051  2.94654543\n",
      "  3.53017218 10.1364707   3.75216593  3.52375504  3.13586459  6.85071392]\n",
      "0:00:04.236459\n",
      "Iteration :  86 Total reward:  -0.6600000000000003\n",
      "[ 3.11888503  5.28529192  4.9603008   1.54405974  3.82985293  2.94654543\n",
      "  3.60574003 10.23543005  3.75216593  3.5929403   3.03622076  6.85071392]\n",
      "0:00:04.436810\n",
      "Iteration :  87 Total reward:  -0.6200000000000002\n",
      "[ 2.17009183  5.16039361  4.9603008   1.42355409  4.30552494  2.94654543\n",
      "  3.66412295 10.5075835   3.75216593  3.05530366  3.32387038  6.85071392]\n",
      "0:00:03.939776\n",
      "Iteration :  88 Total reward:  -0.39\n",
      "[ 2.06608371  4.78743608  4.9603008   1.34013984  4.20145765  2.94654543\n",
      "  3.91772538 10.44088161  3.75216593  2.28481603  3.01451425  6.85071392]\n",
      "0:00:04.057364\n",
      "Iteration :  89 Total reward:  -0.24000000000000002\n",
      "[ 2.47006887  4.59329207  4.9603008   1.28030057  4.02981896  2.94654543\n",
      "  3.98870447 10.63351631  3.75216593  2.21774532  2.81718171  6.85071392]\n",
      "0:00:04.378975\n",
      "Iteration :  90 Total reward:  -0.4\n",
      "[ 1.87018435  4.19602267  4.9603008   1.37226009  4.09901161  2.94654543\n",
      "  3.89305721 11.10763275  3.75216593  2.51363047  3.41292381  6.85071392]\n",
      "0:00:04.141893\n",
      "Iteration :  91 Total reward:  -0.37\n",
      "[ 1.94928161  3.96810426  4.9603008   0.88584436  3.72882387  2.94654543\n",
      "  4.21939638 10.73973083  3.75216593  2.12374746  2.9959161   6.85071392]\n",
      "0:00:04.094764\n",
      "Iteration :  92 Total reward:  -0.31\n",
      "[ 2.04821853  4.3144889   4.9603008   1.56001485  3.41647122  2.94654543\n",
      "  4.32011336 10.52326262  3.75216593  2.02271538  3.1262933   6.85071392]\n",
      "0:00:04.355949\n",
      "Iteration :  93 Total reward:  -0.33999999999999997\n",
      "[ 1.99475235  4.46930292  4.9603008   1.16173229  2.82669319  2.94654543\n",
      "  4.40340363 10.25744685  3.75216593  2.07028229  2.95986847  6.85071392]\n",
      "0:00:04.320714\n",
      "Iteration :  94 Total reward:  -1.1900000000000006\n",
      "[ 1.93298294  4.50125446  4.9603008   2.05746968  3.08795767  2.94654543\n",
      "  3.99376427 10.41433647  3.75216593  2.01745409  2.58568649  6.85071392]\n",
      "0:00:04.108148\n",
      "Iteration :  95 Total reward:  -0.43000000000000005\n",
      "[ 2.00256933  4.21606078  4.9603008   1.97764504  3.07168154  2.94654543\n",
      "  4.07673151 10.73849761  3.75216593  2.35169834  2.71893658  6.85071392]\n",
      "0:00:04.117533\n",
      "Iteration :  96 Total reward:  -1.1900000000000006\n",
      "[ 2.4027552   4.36544358  4.9603008   1.65173674  3.50879781  2.94654543\n",
      "  4.13081575 10.6975464   3.75216593  2.26466084  2.90461404  6.85071392]\n",
      "0:00:03.889901\n",
      "Iteration :  97 Total reward:  -0.6000000000000002\n",
      "[ 2.34800736  4.26958142  4.9603008   2.49089385  3.46908885  2.94654543\n",
      "  4.17841363 10.5276906   3.75216593  2.32613795  2.96606734  6.85071392]\n",
      "0:00:03.838453\n",
      "Iteration :  98 Total reward:  -0.28\n",
      "[ 2.40761813  3.62981999  4.9603008   2.27946139  3.10973612  2.94654543\n",
      "  3.97261718 10.86693033  3.75216593  2.40283573  2.41631886  6.85071392]\n",
      "0:00:04.017590\n",
      "Iteration :  99 Total reward:  -0.24000000000000002\n"
     ]
    }
   ],
   "source": [
    "total_rewards = DQN(100,1e-1,0.99,0.9,env,100,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.32999999999999996, -0.32, -0.21000000000000002, -0.38, -0.21000000000000002, -0.21000000000000002, -0.26, -0.38, -0.29000000000000004, -0.27, -0.32, -0.23, -0.25, -0.27, -0.23, -0.21000000000000002, -0.22, -0.43000000000000005, -0.21000000000000002, -0.37, -0.21000000000000002, -0.23, -0.21000000000000002, -0.21000000000000002, -0.22, -0.42000000000000004, -0.31, -0.28, -0.25, -0.31, -0.23, -0.4700000000000001, -0.32, -0.21000000000000002, -0.28, -0.3, -0.26, -0.29000000000000004, -0.24000000000000002, -0.33999999999999997, -0.22, -0.37, -0.22, -0.28, -0.25, -0.8400000000000003, -0.21000000000000002, -0.31, -0.23, -0.25, -0.32999999999999996, -0.21000000000000002, -0.21000000000000002, -0.36, -0.33999999999999997, -0.22, -0.22, -0.41000000000000003, -0.23, -0.25, -0.5200000000000001, -0.32, -0.21000000000000002, -0.26, -0.22, -0.4800000000000001, -0.28, -0.42000000000000004, -0.5500000000000002, -0.33999999999999997, -0.42000000000000004, -0.22, -0.32, -0.5200000000000001, -0.27, -0.37, -0.21000000000000002, -1.1600000000000006, -0.23, -0.36, -0.43000000000000005, -0.7100000000000002, -0.7300000000000002, -0.5200000000000001, -0.22, -0.21000000000000002, -0.6600000000000003, -0.6200000000000002, -0.39, -0.24000000000000002, -0.4, -0.37, -0.31, -0.33999999999999997, -1.1900000000000006, -0.43000000000000005, -1.1900000000000006, -0.6000000000000002, -0.28, -0.24000000000000002]\n"
     ]
    }
   ],
   "source": [
    "print(total_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAbEUlEQVR4nO3df5Ac5X3n8fcXCZxfFwFaSpaRNzIropgQxTIbhJfDUDKhbCcV2ankLiZyhCuOIImK3HGuM1ekyne5qqvL5SAJJR94w0UBFMVJiAkEE35JBjmskb2KHAUQinYIltcWoCWxzkn+MDbf+2N7NrOjmdme6e7pp/v5vKqmdqa3d54f/ex3nn7m6afN3RERkfo7o+wMiIjIcCjgi4hEQgFfRCQSCvgiIpFQwBcRicTysjPQy8jIiK9du7bsbIiIVMbBgwfn3P28Tr8LOuCvXbuW6enpsrMhIlIZZvaVbr/TkI6ISCQU8EVEIqGALyISiUwB38zONbPHzexY8vOcDvu8w8y+YGbPmdlhM/v3WdIUEZHBZO3h3wzsdfcLgb3J63b/AvyCu/8w8F7gd8zs7IzpiohIn7IG/C3A3cnzu4EPtO/g7n/n7seS518HXgU6Thkqyp1PNZhqzC3aNtWY47pdX1zY3txnqjHHnU81FvZpPi8jf61ppylDr+13PtXg9z7fWPSewyhfmrKVKWv+Wv++rDYUeh23GnZeq1Q3w5A14K9y9xPJ85eBVb12NrNLgbOArrVtZtvNbNrMpk+ePJkxe/M2rFnBjj2HFg78VGOOHXsOcfm6lQvbN6xZwfX3HuT6ew+yYc2KhX02rFmRSx4GyV9r2mnK0Gv7sjPgf3z2BZYlR3xY5UtTtjJlzV/r35fVhkKv41bDzmuV6mYo3L3nA3gCeLbDYwvwjbZ9/7HH+6wGjgKXLZVm83HJJZd4Xp6eOekbf+Mxv/XRF3zjbzzmT8+cPG37xZ94xC/+xCOn7TMMzXxcO/kFv/gTjyxK++mZk37HkzOpytBr++T+mSXTKLJsedZrsz7a09n2+wc6bu9Vtqz566cNtea7+bw1f4Meh25l6FZPWY511vcsoj30yt/TMyf94k884h+a/MLQ/6/LAEx7l5i6ZA/f3a9294s7PB4AXjGz1QDJz1c7vYeZfT/wWeAWd38mywfUoCbGRti6aZTb982wddMoE2Mjp23/yMRaPjKx9rR9hpm/pxuv8fp33ljY3tojSVOGXtt/6YqxJdMosmx51mu/Zzy9ypY1f/20oaLOCLqVoYgebtb3LKI99MofwOvfeYOpxmtD/78OTdYhnQeBbcnzbcAD7TuY2VnA/cA97n5fxvQGNtWYY/eB49y4eR27Dxxf1Fib23dNvcSuqZdO26dfg4zJTzXm2DX1EhNjKzlz2Rlcf+9BbnvsKDv2HGLntRuZGBtZsgyXj61k19RLi7Y333P3geP83ucbC3/fLY28y9mav6z12mpibISd125kx55Di8rwS1eMddzeq2yd8tfP2G8/bag13880XlvY/kzjtYW8Hp491fe4c7c67lZPWYJe1vfslte8xtvb83f9vQc5c9kZuba/yurW9U/zAFYyPzvnGPNDP+cm28eBu5LnW4HXgS+3PN6R5v3zGtJpnkK2D3U0hziap9XN0/Hm60FP/7ql136a2Svt9b/+sP/Axx/yWx99YaAyTO6fWfSek/tnfO3HH/LJ/f86dNCeRtHl7LZPFrc++kLHMnTbnrYMrfXaK99LHcduZW3NX3te+62zNPunrY9+DPKevfKad1tp5m/9rz9cWPsLET2GdDIF/KIfeQX8NOO9eY6nNv92qXHKbuP2ncYc045ZN//23b+5b9F73vHkjE/un1lUtjzGNZcqZ9bx3l5/3+93Gnm9f7e/T9uG0oz551WGft8rrUHfc1h57fa/1Z5ev/krUl5pRx/wy5KmB5S1dzdIukX1pPLsPTb12wNP2zNPK++y9XNGkEfaRZxhlXXWNoz8FV22YaStgF+CND2MTr2ZYcyA6DeNrL3grPqpp26zdLLM3slzVlPaM4K80g5xlk4vebSn0GcRFZ22Av6QpenF5d0T7fQeefVO+u1lF/EPMuxeXz898byVmXaZyuxdtyvyrLXotBXw+5T3uHPznzbNmHyVel55pTfscd1BxsU7HcOiZEm7zDHorELJu3r4kQX8InoaZfYY8lJUGXrVd97HIksZqtDrC6mXXEVl1l9eafcK+FoeuYM084wHmafdPk++19+Epoi59E296vvw7KlFdd/c9/DsqaGWocjy55l2EfPuB1HVNWzybG9Bpt3tkyCER9lj+L16VWk/jeswHjusXk8Zs33SlKGKvb6yzyh1plEe1MPv31K9qrQ9qdZP7YmxET714UsA2LlvprTeVxqtPbRmGZrbB+159Or1FdGDzqsMVev1panLonvgoZxphG7oZ0LdPglCeFRhDH+QnlTZva80iuihDXu2T4y9zEHOPHvtl1UV2nqZijgO9Ojh2/zvwzQ+Pu7T09NDT/fOpxoLi5U1TTXmmNz/ItvffcHC9qnGHNffe5AfOX8FL7z8zVQ9mOZCU1s3jbL7wPGgez1F5LXTex6ePbWovu98qsGyM+A7b8ANV44t/N3h2VMLr8ssQ8i6td1OdVd03cRW94PKu57M7KC7j3f8ZbdPghAeZY/ht8s6Hl/FHmcZa7CENDOn7sqYeSWny/M4oDH8fLSOS35y3wwAn/rwJQvj80uNrZY5FjyIIsbV08xYynP8t8zZNaErsm6q1tbLNNQ22u2TIIRHaD38phh6jEWP4ac5QypzTZW6U92EYdhj+Orh96nOPcY0s1om97848KyCfmYs5VHP/fYyqzp3fBDqgWeTV1sZ+nHo9kkQwiO0Hn7de0VpyjeM8fWy6rnux1fyE3JbIcalFYa9Vk0o64Bk1Wy4adbxz7oGfrf3KbMu05Q/BKG0t1DyUYZQ20qUAX/Yn8Ahf+L3a5B1/FuVcaaQpyp8RxNK/YWSj7KE2FaiCfhl360+1E/8fuTRw0+zT6g9wzRlCyXvobS3UPIxbKGWO5qA36m3kfW+rf0K8RM/rbx75lWri7RlC6lXG0odh5KPYQmpDbTrFfBrNUun7LvVV30GT5oZA2lnFRS9Nk5rOnnNoklbtn6vEygq30W3t7T5rnq7H0RrW2nWR2tbCXZ2V7dPghAeg47hl3G3+pA/8YetqLoIrY7LXKN+GHVR9e9ihiW0OiCWIR33f63sPO9DmkYo47ohCP2ep3noNx9553tY7a2q38UMWyjt0j2igB/aJ60Uo+zx4kHbWdn5HlRV8z1sodRTr4BfqzF8XT1YfyGMF6dpZ+3j31ONOXZNvcTE2MpKjXOXVd9Vu+o5hHaZSrdPghAeoV1pK+Wq0hlca96a04N1p7NqpN2v0PKK1sOXOuhnrfcQNNc5f/ub/w2Hv3ZqYWXV5u9CzXdT2fVdlfX0y66ndr3Ww1fAr6DQGljZQq6P2x47yu37Zrhx8zpuumZ9qXkpS5bjE1L9hdzOWvUK+LUaw4/FhjUr2LHn0MI4YbMntGHNipJzVo5Q66My47oFG/T4hFZ/obazvnQb6wnhUcQYfr/TyEKddhbSNLAQhFYfoY3rlm3Qaayh1V9o7awTYpmlk0a/n9KhfqpPjI2wddMot++bYeum0SDHNocptPrQjLHF+j0+odZfaO2sX1GO4ff7ZVCIXx6FmKcyqT7CFvLxCenG73ko9CbmwLnA48Cx5Oc5Pfb9fmAW2JnmvYucltnvRRKhXFThHu7pbllUH2EL/fikzV/o5Wii4CGdm4G97n4hsDd53c1/B/bnkGYm/X4ZFNqXR6Ge7pZF9RG20I9Pt8XwDs+eWvS/fnj2FL981QUL+Q6tHKl0+yRI+wCOAquT56uBo132uwT4NHAdJfbw+/2Ursqnuohk034WX9X/fQru4a9y9xPJ85eBVe07mNkZwK3Ax3JIL5N+exuh906kHqq2lEDddDqL73cZ7CpYnmYnM3sCeHOHX93S+sLd3cw6fQv8K8DD7j5rZkultR3YDjA6Opome33pdIHExNhI14PY7/4ig2jOBmsGlOaXgzuv3Vh21mqvta4nxka4bGzlotfNWTk3bl5X+f/7zLN0zOwocJW7nzCz1cCT7r6+bZ8/BK4A3gC+DzgL+D/u3mu8X1faDkFVrh6MQVkzQNK0gTq3k15la34Qhzwrp13RV9o+CGxLnm8DHmjfwd1/3t1H3X0t88M69ywV7GU4Qr3OIEZlzfFO0wbq3E5uuHLstLqeGBtZdNZ10zXrF4Z3yp60kUm3wf20D2Al87NzjgFPAOcm28eBuzrsfx0BTMusglBuciHDUeZxSJN2Wfkr62r3rOmWlW9iuQFK3QxzlkBI1xnEKIQZIWnaQBntJIS6GURZ+e4V8KNbWqFKhjVLILTrDGJU9mywNG2grHZS1dkyQea72ydBCI/Ye/hNRfaqqtp7kvykaQMhtJOqnoUOO9+oh19dRfeqyu5ZSvnStIGy20lVz0KDy3e3T4IQHrH38EPoVYmUrar/BxrDl76U3asSCUFV/w9CzHeUyyOLiNSVbnEohdNaMCLhU8CXXNT5SkyRulDAl1wEOedYFtFZmCjgS26qfr/PutNZmKRaHlkkjfY5x5eNrVTQD0jrWViVVn+U/KiHL7loXVO8NisL1pDOwuKmgC+5CHHOsZwuuCs/Zag0D18kEu13dmp/LfWgefgiorMwUQ9fRKRO1MMXqYHQ59GXmb/Q6yYUCvgiFRH6PPoy8xd63YRCQzoiFdIMZKHOoy8zf6HXzbBoSEekJkKfR19m/kKvmxAo4ItUSOjz6MvMX+h1EwIFfJGKCP1q5jLzF3rdhEIBX6QihjGPPstslzLn+esag3T0pa2ILNDVuNXX60tbrZYpIgu0oma9aUhHRBbRbJf6UsAXkUU026W+FPBFZIFmu9SbAr6ILNBsl3rTLB0RkRrR0goiIqKALyISi0wB38zONbPHzexY8vOcLvuNmtljZnbEzJ43s7VZ0hURqaoy1+7P2sO/Gdjr7hcCe5PXndwD/Ja7vx24FHg1Y7oiIpVU5tr9Wa+03QJclTy/G3gS+HjrDmZ2EbDc3R8HcPd/ypimiEhllXk1c9Ye/ip3P5E8fxlY1WGfHwS+YWafMbNDZvZbZras2xua2XYzmzaz6ZMnT2bMnohIeMq6mnnJgG9mT5jZsx0eW1r38/n5nZ3meC4HrgA+BvwYcAFwXbf03H3S3cfdffy8887rpywiIqmUfQ/csq5mXjLgu/vV7n5xh8cDwCtmthog+dlpbH4W+LK7v+ju3wb+HHhnnoUQEelHmePoZV7NnHVI50FgW/J8G/BAh32+BJxtZs3u+mbg+YzpiogMrHUc/bbHjg51Cegyr2bOdKWtma0E/gQYBb4C/Dt3/wczGwducPePJvv9OHArYMBBYLu7f2up99eVtiJSpNseO8rt+2a4cfM6brpmfdnZyUVh6+G7+2vAezpsnwY+2vL6cWBDlrRERPLUPo5+2djK2i8FrSttRSQ6sa4KqoAvItGJdVVQrZYpIlIjWi1TRKJX9tz7ECjgi0gUypx7H4qsa+mIiFRCmWvYhEI9fBGJRllr2IRCAV9EolHWGjahUMAXkSjEOve+lQK+iEQh1rn3rTQPX0SkRjQPX0REFPBFRGKhgC8ilaGrZbNRwBeRytDVstnoSlsRqQxdLZuNevgiUimxXy2bhQK+iFRK82rZy8dWsmvqpUVj+hrP700BX0Qqo/Vq2V/dvA6A6+89yFRjTuP5KWgMX0Qqo/1q2U99+BKuv/cgO/fN8MLL39R4/hLUwxeRyrjhyrFFAX1ibISPTKxlqvGaxvNTUMAXkcqKffXLfingi0glafXL/ingi0glafXL/mm1TBGRGtFqmSIiooAvIhILBXwRkUgo4IuIREIBX0QkEgr4IiKRyBzwzexcM3vczI4lP8/pst//MrPnzOyImd1uZpY1bRERSS+PHv7NwF53vxDYm7xexMwmgMuBDcDFwI8BV+aQtoiIpJRHwN8C3J08vxv4QId9HPgu4CzgTcCZwCs5pC0iIinlEfBXufuJ5PnLwKr2Hdz9C8DngBPJ41F3P9Lpzcxsu5lNm9n0yZMnc8ieiIhAyvXwzewJ4M0dfnVL6wt3dzM7ba0GM1sHvB1Yk2x63MyucPfPt+/r7pPAJMwvrZAmfyIisrRUAd/dr+72OzN7xcxWu/sJM1sNvNphtw8Cz7j7PyV/85fAu4DTAr6IiBQjjyGdB4FtyfNtwAMd9jkOXGlmy83sTOa/sO04pCMiIsXII+D/T+DHzewYcHXyGjMbN7O7kn3uAxrA3wJ/A/yNu/9FDmmLiEhKme9p6+6vAe/psH0a+Gjy/DvA9VnTEsnDnU812LBmxaLb4U015jg8e4obrhwrMWcixdKVthKdDWtWLLozUvPOSRvWrCg5ZyLFytzDF6ma5p2Rduw5xNZNo+w+cHzRnZNE6ko9fInSxNgIWzeNcvu+GbZuGlWwlygo4EuUphpz7D5wnBs3r2P3geO68bVEQQFfotMcs9957UZuumb9wvCOgr7UnQK+ROfw7KlFY/bNMf3Ds6dKzplIscw93NULxsfHfXp6uuxsiIhUhpkddPfxTr9TD19EJBIK+CIikVDAFxGJhAK+iEgkFPBFRCKhgC8iEgkFfBGRSCjgi4hEQgFfRCQSCvgiIpFQwBcRiYQCvohIJBTwRUQioYAvIhIJBXwRkUgo4IuIREIBX0QkEgr4IiKRUMAXEYmEAr6ISCQU8EVEIqGALyISCQV8EZFIKOCLiEQiU8A3s581s+fM7A0zG++x33vN7KiZzZjZzVnSFBGRwWTt4T8L/DSwv9sOZrYM+CTwPuAi4ENmdlHGdEVEpE/Ls/yxux8BMLNeu10KzLj7i8m+nwa2AM9nSVtERPozjDH884GvtryeTbaJiMgQLdnDN7MngDd3+NUt7v5A3hkys+3AdoDR0dG8315EJFpLBnx3vzpjGl8D3tryek2yrVt6k8AkwPj4uGdMW0REEsMY0vkScKGZvc3MzgJ+DnhwCOmKiEiLrNMyP2hms8C7gM+a2aPJ9reY2cMA7v5tYAfwKHAE+BN3fy5btkVEpF9ZZ+ncD9zfYfvXgfe3vH4YeDhLWiIiko2utBURiYQCvohIJBTwRUQioYAvIhIJBXwRkUgo4IuIREIBX0QkEgr4IiKRUMAXEYmEAr6ISCQU8EVEIqGALyISCQV8EZFIKOCLiERCAV9EJBIK+CIikVDAFxGJhAK+iEgkFPBFRCKhgC8iEgkFfBGRSCjgi4hEQgFfRCQSCvgiIpFQwBeR0tz5VIOpxtyibVONOe58qlFSjupNAV9ESrNhzQp27Dm0EPSnGnPs2HOIDWtWlJyzelpedgZEJF4TYyPsvHYjO/YcYuumUXYfOM7OazcyMTZSdtZqST18ESnVxNgIWzeNcvu+GbZuGlWwL5ACvoiUaqoxx+4Dx7lx8zp2Hzh+2pi+5EcBX0RK0xyz33ntRm66Zv3C8I6CfjEU8EWkNIdnTy0as2+O6R+ePVVyzgbTbdbRdbu+GMRsJAV8ESnNDVeOnTZmPzE2wg1XjpWUo2y6zTq6fN3KIGYjZZqlY2Y/C/xX4O3Ape4+3WGftwL3AKsABybd/XezpCsiEqJes45++C0rSp+NlLWH/yzw08D+Hvt8G/hP7n4RcBnwq2Z2UcZ0RUSC1G3WUQizkTIFfHc/4u5Hl9jnhLv/dfL8m8AR4Pws6YqIhKrbrKMQZiMN9cIrM1sLbAQO9NhnO7AdYHR0dCj5EhHJQ+uso4mxES4bmx+7/+WrLuCOJ188bfuwh3WW7OGb2RNm9myHx5Z+EjKz7wP+DPgP7v7/uu3n7pPuPu7u4+edd14/SYiIlKrbrKOnZ14LYjaSuXv2NzF7EvhYpy9tk9+fCTwEPOrut6V93/HxcZ+e7viWIiLSgZkddPfxTr8rfFqmmRnwf4Ej/QR7ERHJV6aAb2YfNLNZ4F3AZ83s0WT7W8zs4WS3y4EPA5vN7MvJ4/2Zci0iIn3L9KWtu98P3N9h+9eB9yfP/wqwLOmIiEh2utJWRCQSCvgiIpHIZZZOUczsJPCVAf98BIhtyb0YywxxljvGMkOc5e63zD/g7h3ntAcd8LMws+luU5PqKsYyQ5zljrHMEGe58yyzhnRERCKhgC8iEok6B/zJsjNQghjLDHGWO8YyQ5zlzq3MtR3DFxGRxercwxcRkRYK+CIikahdwDez95rZUTObMbOby85PUczsrWb2OTN73syeM7NfS7afa2aPm9mx5Oc5Zec1b2a2zMwOmdlDyeu3mdmB5Jj/sZmdVXYe82ZmZ5vZfWb2gpkdMbN31f1Ym9l/TNr2s2b2R2b2XXU81mb2+2b2qpk927Kt47G1ebcn5T9sZu/sJ61aBXwzWwZ8EngfcBHwoRrfTrHbrSNvBva6+4XA3uR13fwa83dOa/pN4LfdfR3wj8AvlpKrYv0u8Ii7/xDwo8yXv7bH2szOB24Ext39YmAZ8HPU81j/AfDetm3dju37gAuTx3bgjn4SqlXABy4FZtz9RXf/FvBpoK8btVRFj1tHbgHuTna7G/hAOTkshpmtAX4CuCt5bcBm4L5klzqWeQXwbuaXGcfdv+Xu36Dmx5r5xR2/28yWA98DnKCGx9rd9wP/0La527HdAtzj854Bzjaz1WnTqlvAPx/4asvrWSK4f27brSNXufuJ5FcvA6tKylZRfgf4z8AbyeuVwDfc/dvJ6zoe87cBJ4FdyVDWXWb2vdT4WLv714D/DRxnPtCfAg5S/2Pd1O3YZopxdQv40el160ifn3Nbm3m3ZvaTwKvufrDsvAzZcuCdwB3uvhH4Z9qGb2p4rM9hvjf7NuAtwPdy+rBHFPI8tnUL+F8D3tryek2yrZaSW0f+GfCH7v6ZZPMrzVO85OerZeWvAJcDP2VmLzE/XLeZ+bHts5PTfqjnMZ8FZt39QPL6PuY/AOp8rK8G/t7dT7r768BnmD/+dT/WTd2ObaYYV7eA/yXgwuSb/LOY/5LnwZLzVIget458ENiWPN8GPDDsvBXF3f+Lu69x97XMH9t97v7zwOeAn0l2q1WZAdz9ZeCrZrY+2fQe4HlqfKyZH8q5zMy+J2nrzTLX+li36HZsHwR+IZmtcxlwqmXoZ2nuXqsH83fa+jugAdxSdn4KLOe/Zf407zDw5eTxfubHtPcCx4AngHPLzmtB5b8KeCh5fgHwRWAG+FPgTWXnr4DyvgOYTo73nwPn1P1YA/8NeAF4FrgXeFMdjzXwR8x/T/E682dzv9jt2DJ/98BPJvHtb5mfxZQ6LS2tICISiboN6YiISBcK+CIikVDAFxGJhAK+iEgkFPBFRCKhgC8iEgkFfBGRSPx/m5kKJOuiDnUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(total_rewards,'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 - left\n",
    "1 - down\n",
    "2 - right\n",
    "3 - up\n",
    "\n",
    "0|1|2|3\n",
    "4|5|6|7\n",
    "8|9|10|11\n",
    "12|13|14|15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 0.0, False, {'prob': 1.0})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.99*0.92 - 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
